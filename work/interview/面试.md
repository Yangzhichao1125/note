## 模拟面试



1、先简单地做一个自我介绍吧

```
我是2017年毕业于福建福州的闽江学院，是电子系的，在大三的时候也就是15年开始学的Java，然后先后做过一些单体项目以及做过一些dubbo和spring cloud 的微服务项目，然后对现在一些比较常用到的技术还是比较会用的，比如说springboot，spring cloud 以及对这些项目的优化，比如说redis的缓存优化，zuul 动态路由灰度发布，mysql的分库分表等等的这些都是做过的。工作之余，我也是对新的技术比较感兴趣，对k8s、docker这类的东西有过一些了解。业余爱好会去游游泳健健身，弹弹吉他之类的事。
```

2、你说你做过dubbo和spring cloud是吧，你说说他们之间的区别吧

```
两者最大的区别是dubbo使用netty的nio框架，是基于tcp协议，配合hession协议的rpc框架。spring cloud 是http协议 + rest接口调用的方式收发请求。
http报文较长，消耗的带宽较多，不过现在的话带宽这方面问题对余互联网公司来说并不是什么瓶颈问题，如何要优化的话，可以通过压缩等方式减少带宽。
```

3、简单地说一下你对分布式的理解

```
首先从字面上的意思来看，分布式就是不同的业务分开部署到不同的地方。比如说mysql数据库服务和web服务，就是提供给客户访问的服务，分开部署到不同的机子上面，这也可以叫做分布式。这是常用的分布式的一种。然后另一种分布式就是现在比较流行的微服务的架构，就是可以把一个系统根据业务拆分成多个微服务，然后每个业务都可以有自己的一个开发团队，进行自己的一个技术选型，独立的部署，独立的运行。这样做是有很大的一个好处的，可以解藕各个模块，让开发的效率提高很多。这就是我对分布式的一个理解。
```

4、说一下spring cloud 的组件

```
首先我们是一个微服务集群，肯定是需要一个注册中心去进行一个统一的信息管理。将各个服务的名称以及ip地址注册到这个注册中心去。然后当别人要去调用的时候直接去注册中心的列表里去找根据服务名称找到对应的IP进行通信。
在通信过程中，因为是集群模式，所以一个服务会对应多个ip，这时候就要进行负载均衡的一个处理，Spring cloud 用的是ribbo的这么一个组件进行负载均衡获取对应的ip地址
然后就是通信过程是用的feign来调用对应的service接口
如果某个服务挂掉了，可以使用hystrix 来进行熔断或进行服务的降级
这么多的服务，是spring cloud 提供一个统一的配置中心，spring cloud configration
网关zuul 的主要功能就是提供给前端统一的地址的调用，否则前端去控制地址的转发就太麻烦了，第二个作用是进行一个统一鉴权操作，这些操作统统交给网关系统zuul去处理，当然你要发布新服务，以及服务升级的是时候可以自己写一个动态路由以及灰度发布的这么一些操作。
```

5、鉴权是怎么做的

```
现在比较流行的是一个rbac的权限管理这么一套理念。主要有这么几个概念，用户，角色，权限，资源。我们是基于角色进行权限的管理的，根据用户去拿到他对应的角色，然后拿到对应的一个权限。我们的权限和资源是一对一的关系的，所以我们是把资源这一块给省略掉了。然后关系的这一块用户和角色是多对多的关系，角色和权限也是多对多的关系。这就是我们对鉴权这一块的设计。
```

6、你们用的权限框架是什么

```
我用过两个，一个是前后端分离的项目用的是shiro，一个是分布式项目用的是spring security。都有用到过。
```

7、知道你这个url地址都可以去访问么

```
我们是需要用户先去登陆的，然后用到上面所说的跟去这个用户的角色判断是否有访问资源的权限
```

8、简单地介绍一下jwt

```
普通的一个登陆成功的话就是直接返回一个消息，而jwt的话，将权限以及用户的信息资源缓存起来，比如说缓存到zuul当中。下次同一个用户请求进来，通过http的head中的token 通过解析token和jwt 获取权限数据，不需要再查询数据库了。所以jwt说穿了就是对权限数据的一个缓存。
```

9、你们项目当中的分布式事务是怎么处理的

```
分布式事务有很多种
有两阶段提交，但是这种方式的话效率太低了，第一次发给全部的数据库，问他们是否准备好，如果准备好才进行第二次写入操作。这种的话效率比较低。不过安全性是挺高的。
还有一种是TCC，的三阶段提交。一开始我么只是用了阿里的seata框架做了核心链路的分布式事务。后来发现，效率也是优点慢。所以就后面进行优化，又加上了一个可靠消息最终一致性的分布式事务。
具体的做法是这样的：
首先是TCC方式
我们的订单接口是比较多，访问也很频繁，所以我们订单接口单独拆分出来做一个服务，当作是接口的转发。
用户下订单的是侯会经过订单核心接口，库存接口，积分接口。然后这些接口都是有对应自己的数据库。这部分是用阿里的seata，实现的tcc事务，主要就是用一个seataserver 的这么一个服务将你要做的这些事务进行一个注册，成功就一起成功，如果失败，就根据你注册的这些事务对其数据库进行一个回滚操作。
在优化后，我们是将仓储服务也是加到分布式事务当中了。我们的仓储服务也就是 wms 的算法十分复杂，有时返回一个接口的时间要十多秒，有时甚至要几十秒。用同步的方式显然是不合适的。所以就引入了rocketMQ 对事务消息的支持。
刚才的下订单流程也就要做相应的改变了。
用户下单，先走订单接口，然后发消息给rocketMQ，发的是一个halfMessage，主要的作用就是问问rocketMQ是否准备好了，如果准备好了，MQ会发送一个success message给订单调用接口，如果没有收到消息就会重新发送halfMessage给rocketMQ。直到成功。
成功后就是走上面说的那一条核心交易链路。
这里又要判断核心链路是否成功，如果失败，得发消息到支付系统进行退款，还要发消息到订单系统将订单状态修改成已取消，还要发送消息到MQ取消之前到success message。
如果成功了就发送消息到MQ 并让其执行WMS的后续操作，因为用户对于什么时候发货，哪里发货的这些消息是不那么着急知道的。所以可以走异步的方式去走MQ。而这边就涉及到MQ的重复消费和消息可靠性的问题了。这边是用了wms 的ack方式去通知MQ消息是否消费成功。这边的幂等性也好做，因为是插入操作，所以用数据库的主键唯一性就能解决幂等的问题。
```

10、redis 缓存和mysql的数据一致性

```
双写一致性通常有三种解决方法，一个是先写数据库，然后删缓存。一个是先删缓存再更新数据库。但这两种都有问题，比方说先写数据库，在写完还没更新缓存的是侯又有请求进来，那查到的数据就是不一致的。还有就是先删缓存，这时候另一个请求又过来的了，那查到原来的数据放缓存里，那两者也是不一致的。
还有一种就是串行化，能保证你数据的强一致性，用的思想也是跟锁的思想一样。同过你这个要更改请求的id 我去路由到对应的JVM 当中去做一个数据库操作，在操作过程中读的请求是堵塞的。因为是同一个jvm，你只要在路由到同一个线程去处理，就能保证同一个id的请求是线程安全的。但是这样做的话会导致系统的吞吐量降低地非常多。所以对双写一致性的这个问题，目前的方案还是没有一个十全十美的方案。我们的做法是把redis 删除缓存单纯拆分成一个服务。当数据修改够发消息到这个服务，进行缓存的删除。同时还会去删除本地的guava cache。
```

11、redis用来做缓存以外还做过什么其他的东西

```
首先redis是有5种数据类型的
Stirng 和 hash 我们主要是用来当缓存的
然后list队列可以做一些消息通知，对那些非核心的东西可以用这个，比较重要的消息就要用MQ发送，因为会有消息丢失重发，死信队列等等的问题
sort的话我们会做一个喜欢此商品的人同时也喜欢哪些其他商品的这么一个推广的功能
zsort主要就是做一个排名了，比如锁热搜商品，每日收藏最多的商品等等。用于点赞数收藏数的一个累加每日统计一次

还有就是redis的分布式锁的机遇redison的那套东西。
```

12、redis分布式锁怎么实现

```
redis分布式式用起来还是比较简单的，用到redison去实现，类似于reentrantlock的使用。
底层就是用到redis 集群以及lua脚本去实现
首先客户端根据你的这个key进行hash 然后找到redis集群中的一台机器
然后发送lua（复杂的业务封装，保证原子性）脚本给redis，将这个key设置一个时间为30秒的过期时间
这时有其他客户端来请求会背堵塞，并一直去循环尝试加锁。
看门狗的机制可以使第一个客户端一直持有这把锁，延长过期时间。
过程中还支持可重入加锁。
调用unlock或者服务宕机，key的加锁次数变为零后就释放锁
只要redis不发生脑裂，一般分布式锁都没什么问题。
```



13、zookeeper 分布式锁怎么实现

```
首先分布式锁是在多台机器上对统一个资源的锁定这么一个操作。因为是在不同的机器上，所以synchronize和reentrantlock是在同一个jvm的，不能控制公共资源。因此可以基于redis或者zookeeper实现分布式锁。zookeeper里面有个动态节点的这么一个概念，在我访问的是侯我去判断对与某个id或者某个标识是否有创建过节点，如果没有我就创建，如果有我就在前面的那个节点前再创建一个顺序节点。从而进入阻塞状态。这里用到的是curator，用法跟redison也差不多。主要是这个curator用的是顺序节点，所以可以避免zookeeper的羊群效应。就是多个节点进行同一份资源的争抢，增加网络的开销。
```

14、数据库优化做过哪些

```
数据库优化做的还是挺多的。比方说再建表的是侯选好数据类型，一些数值比较小的用tinnint而不是用int或者longint。对于固定长度的字符串用char而不是用varchar，另外就是写的sql，进来去命中索引，有些查询操作是不走索引的，比如说like %，is null ，where 后面有复合函数，索引的最左匹配原则，类型转换等等。还有就是分库分表的这么一些方案。
```

15、分表如何看数据在哪张表当中

```
首先数据插入的时候根据实现定好的标识插入对应的库对应的表。查的时候也是根据这个方式获取。通常来说是有两种分表策略，一个是根据时间去划分，一个是根据id的hash去划分。这两者我们也是都有用过。在工厂的时候，每段时间的或者说每个月的数据是大小是差不多的，我们是根据这个range这个方式，给每个月单独分出一个库或者单独分出一个表，如果要查那年那月的数据就到哪张表去查。特别是做报表的时候，在同一张表中去分析数据，效率会比较高。而id去做hash操作主要是互联网产品每个时间点数据量都差别比较大，容易出现第二个月数据比第一个月数据多很多的这么一种情况。我们在分库分表前也是对mysql的性能做过一番研究的，只要单表的数据超过1000万，查询效率就会有断崖式降低这么个情况。所以我们是每500万份数据放在一个表里面。
```

16、数据跨表了，怎么查询

```
首先是根据你的这个id算出具体你的数据是在几张表里，然后查出数据后用unionall的方式将数据结合在一起，在这里一般不使用union，因为union比unionall多了一次排序操作，在数据量大的情况下，性能比较低。
```















